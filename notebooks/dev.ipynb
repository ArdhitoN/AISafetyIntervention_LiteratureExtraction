{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f984882-183a-4d5f-999a-bcb9faac93a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68ca6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.db import AISafetyGraph\n",
    "\n",
    "g = AISafetyGraph()\n",
    "nodes = g.get_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0726ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "input_jsonl = \"batchinput.jsonl\"\n",
    "with open(input_jsonl, \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, node in enumerate(nodes):\n",
    "        line = {\n",
    "            \"custom_id\": f\"req-{i}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/embeddings\",\n",
    "            \"body\": {\n",
    "                \"model\": \"text-embedding-3-small\",\n",
    "                \"input\": node[\"text\"],\n",
    "                \"encoding_format\": \"float\",\n",
    "            },\n",
    "        }\n",
    "        f.write(json.dumps(line) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f379a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded = client.files.create(file=open(input_jsonl, \"rb\"), purpose=\"batch\")\n",
    "\n",
    "batch = client.batches.create(\n",
    "    input_file_id=uploaded.id,\n",
    "    endpoint=\"/v1/embeddings\",\n",
    "    completion_window=\"24h\",\n",
    ")\n",
    "print(\n",
    "    json.dumps(\n",
    "        {\"batch_id\": batch.id, \"status\": batch.status, \"input_file_id\": uploaded.id}\n",
    "    )\n",
    ")\n",
    "\n",
    "create_out = \"embeddings/batch_create.json\"\n",
    "payload = batch.model_dump()\n",
    "with open(create_out, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(payload, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2877bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "batch = client.batches.retrieve(batch.id)\n",
    "print(batch.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af08aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "file_response = client.files.content(batch.output_file_id)\n",
    "with open(\"embeddings/batch_out.jsonl\", \"w\") as f:\n",
    "    f.write(file_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb6f7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import gzip\n",
    "from typing import Iterator\n",
    "\n",
    "\n",
    "def iter_jsonl(path: str | Path) -> Iterator[dict]:\n",
    "    \"\"\"Yield one dict per line. Supports .gz files.\"\"\"\n",
    "    path = Path(path)\n",
    "    opener = gzip.open if path.suffix == \".gz\" else open\n",
    "    mode = \"rt\" if path.suffix == \".gz\" else \"r\"\n",
    "    with opener(path, mode, encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f, 1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                yield json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                raise ValueError(f\"{path}:{i}: {e}\") from e\n",
    "\n",
    "\n",
    "embs = []\n",
    "for item in iter_jsonl(\"embeddings/batch_out.jsonl\"):\n",
    "    custom_id = item[\"custom_id\"]\n",
    "    emb = item[\"response\"][\"body\"][\"data\"][0][\"embedding\"]\n",
    "    embs.append(emb)\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be7c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from usearch.index import Index\n",
    "\n",
    "index = Index(ndim=1536)\n",
    "embs = np.array(embs)\n",
    "keys = [i for i in range(len(embs))]\n",
    "vector = embs[0]\n",
    "index.add(keys, embs)\n",
    "matches = index.search(vector, 10, exact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cb7e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from usearch.index import Index\n",
    "\n",
    "\n",
    "def top_duplicate_pairs_with_texts(\n",
    "    embs, nodes, K=30, top_n=30, metric=\"cos\", dtype=\"f32\", exact=False\n",
    "):\n",
    "    embs = np.asarray(embs, dtype=np.float32)\n",
    "    n, d = embs.shape\n",
    "    keys = np.arange(n, dtype=np.int64)\n",
    "\n",
    "    index = Index(ndim=d, metric=metric, dtype=dtype)\n",
    "    index.add(keys, embs)\n",
    "\n",
    "    batch = index.search(embs, count=K + 1, exact=exact)\n",
    "\n",
    "    best_pair_dist = {}\n",
    "    for i in range(len(batch)):\n",
    "        k = int(keys[i])\n",
    "        m = batch[i]\n",
    "        for nk, dist in zip(m.keys, m.distances):\n",
    "            nk = int(nk)\n",
    "            if nk == k:\n",
    "                continue\n",
    "            a, b = (k, nk) if k < nk else (nk, k)\n",
    "            prev = best_pair_dist.get((a, b))\n",
    "            if prev is None or dist < prev:\n",
    "                best_pair_dist[(a, b)] = float(dist)\n",
    "\n",
    "    # Sort and format output\n",
    "    top = sorted(best_pair_dist.items(), key=lambda kv: kv[1])[:top_n]\n",
    "    results = []\n",
    "    for (a, b), d in top:\n",
    "        results.append(\n",
    "            {\n",
    "                \"id_a\": a,\n",
    "                \"id_b\": b,\n",
    "                \"node_a\": nodes[a],\n",
    "                \"node_b\": nodes[b],\n",
    "                \"distance\": d,\n",
    "                \"similarity\": 1.0 - d,\n",
    "            }\n",
    "        )\n",
    "    return results\n",
    "\n",
    "\n",
    "pairs = top_duplicate_pairs_with_texts(embs, nodes, K=40, top_n=30)\n",
    "for r in pairs:\n",
    "    print(\n",
    "        f\"[{r['id_a']}] {r['node_a']}\\n[{r['id_b']}] {r['node_b']}\\n\"\n",
    "        f\"sim={r['similarity']:.4f} dist={r['distance']:.4f}\\n\"\n",
    "    )\n",
    "    res = g.merge_nodes(r[\"node_a\"][\"id\"], r[\"node_b\"][\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e0af30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad815b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
